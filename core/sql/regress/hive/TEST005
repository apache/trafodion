-- -*- mode: sql; coding: utf-8 -*-
-- Tests for SQL on Hadoop PoC
-- Test simple cases of partitioned tables
-- Very basic test of data types and Unicode
-- Basic test of metadata invalidation
-- Added April 2013
--
-- @@@ START COPYRIGHT @@@
--
-- Licensed to the Apache Software Foundation (ASF) under one
-- or more contributor license agreements.  See the NOTICE file
-- distributed with this work for additional information
-- regarding copyright ownership.  The ASF licenses this file
-- to you under the Apache License, Version 2.0 (the
-- "License"); you may not use this file except in compliance
-- with the License.  You may obtain a copy of the License at
--
--   http://www.apache.org/licenses/LICENSE-2.0
--
-- Unless required by applicable law or agreed to in writing,
-- software distributed under the License is distributed on an
-- "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
-- KIND, either express or implied.  See the License for the
-- specific language governing permissions and limitations
-- under the License.
--
-- @@@ END COPYRIGHT @@@

sh regrhadoop.ksh fs -mkdir  /user/hive/exttables/customer_ddl;
sh regrhadoop.ksh fs -mkdir  /user/hive/exttables/customer_temp;
sh regrhadoop.ksh fs -mkdir  /user/hive/exttables/tbl_utf8;
sh regrhadoop.ksh fs -mkdir  /user/hive/exttables/tbl_type;
--empty folders
sh regrhadoop.ksh fs -rm   /user/hive/exttables/customer_ddl/*;
sh regrhadoop.ksh fs -rm   /user/hive/exttables/customer_temp/*;
sh regrhadoop.ksh fs -rm   /user/hive/exttables/tbl_utf8/*;
sh regrhadoop.ksh fs -rm   /user/hive/exttables/tbl_type/*;

--- setup Hive tables
sh regrhive.ksh -v -f $REGRTSTDIR/TEST005_a.hive.sql;
sh regrhadoop.ksh fs -put $REGRTSTDIR/tbl_utf8.data /user/hive/exttables/tbl_utf8;
sh regrhadoop.ksh fs -put $REGRTSTDIR/tbl_type.data /user/hive/exttables/tbl_type;

log LOG005 clear;

set schema hive.hive;
set terminal_charset utf8;

cqd AUTO_QUERY_RETRY 'OFF';
cqd HIVE_MAX_STRING_LENGTH '25' ;
cqd mode_seahive 'ON';
cqd CALL_EMBEDDED_ARKCMP 'OFF';
cqd HIST_ROWCOUNT_REQUIRING_STATS '50000';
------------------------------------------------------------
-- Testing query plan invalidation in the compiler, but
-- not the executor. Perform DML/DDL operations on a
-- table and try re-executing the old plan as well as
-- getting a query cache hit and updating the changed
-- Hive and HDFS metadata
------------------------------------------------------------

prepare s1 from 
  select c_preferred_cust_flag,
         count(*) 
  from customer_ddl 
  group by 1 
  order by 1
  ;
execute s1;
-- expect 0 rows

prepare s1part from 
  -- selecting part col not supported right now
  select --c_preferred_cust_flag,
         count(*) 
  from customer_bp 
  --group by 1 
  --order by 1
  ;
execute s1part;
-- expect 0 rows

-- insert some data and add one more partition
sh regrhive.ksh -v -f $REGRTSTDIR/TEST005_b.hive.sql;

-- query cache hit, no validation at all
  select c_preferred_cust_flag,
         count(*) 
  from customer_ddl 
  group by 1 
  order by 1
  ;

-- vary query to avoid query cache hit
prepare s2 from 
  select c_preferred_cust_flag,
         count(c_customer_sk) 
  from customer_ddl 
  group by 1 
  order by 1
  ;

prepare s2part from
  -- selecting part col not supported right now
  select --c_preferred_cust_flag,
         count(*) 
  from customer_bp 
  --group by 1 
  --order by 1
  ;
execute s1;
-- because we don't invalidate in the executor,
-- this should still return 0 rows

execute s2;
-- should get an NATable cache
-- hit, we should notice the change in the table
-- and return the correct result

execute s1part;
-- because we don't invalidate in the executor,
-- this should still return 0 rows

execute s2part;
-- although this should get an NATable cache
-- hit, we should notice the change in the table
-- and return the correct result

insert into customer_temp 
select * from customer 
where c_customer_sk between 20000 and 39999;

select * from newtable;
-- no rows, but should know the new table
insert into newtable values ('abc');
cqd query_cache '0';
select * from newtable;
-- expect to see the row, but only because query cache is off
cqd query_cache reset;

insert into hiveregr5.newtable2 values ('xyz');
select * from hiveregr5.newtable2;

-- add a second partition to customer_bp
sh regrhive.ksh -v -f $REGRTSTDIR/TEST005_c.hive.sql;
-- add more files to customer_ddl
sh regrhadoop.ksh dfs -cp /user/hive/exttables/customer_temp/* /user/hive/exttables/customer_ddl;

-- no query cache hit, but NATable cache hit
prepare s3 from 
  select count(*) 
  from customer_ddl 
  ;

-- no query cache hit, but NATable cache hit
prepare s3part from
  -- selecting part col not supported right now
  select --c_preferred_cust_flag,
         count(c_customer_id) 
  from customer_bp 
  --group by 1 
  --order by 1
  ;
execute s1;
-- s1 should still return 0 rows - for now
execute s2;
execute s3;
execute s1part;
-- s1 should still return 0 rows - for now
execute s2part;
execute s3part;

select a,b from newtable;
-- should return 0 rows

insert into newtable values (1, 'def');
select a,b from newtable;

-- overwrite the table with auto-generated partitions
sh regrhive.ksh -v -f $REGRTSTDIR/TEST005_d.hive.sql;

cqd query_cache '0';
prepare s4 from 
  select c_preferred_cust_flag,
         count(*) 
  from customer_ddl 
  group by 1 
  order by 1
  ;
prepare s4part from
  -- selecting part col not supported right now
  select --c_preferred_cust_flag,
         count(*) 
  from customer_bp 
  --group by 1 
  --order by 1
  ;
execute s2;
execute s4;
execute s2part;
execute s4part;
select count(*) from tbl_utf8;
select * from tbl_utf8 where id between 8 and 12;
select * from tbl_utf8 where chapter like '%三%';
select * from tbl_utf8 where chapter like '%海印_昧%';

insert into tbl_utf8_temp 
select * from tbl_utf8;

select count(*) from tbl_utf8_temp;
select * from tbl_utf8_temp where id between 8 and 12;
select * from tbl_utf8_temp where chapter like '%海印_昧%';

select count(*) from tbl_utf8p;
select * from tbl_utf8p where id between 8 and 12;
select * from tbl_utf8p where chapter like '%海印_昧%';

select * from tbl_type;
insert into tbl_type_temp select * from tbl_type;
select * from tbl_type_temp;

log;
