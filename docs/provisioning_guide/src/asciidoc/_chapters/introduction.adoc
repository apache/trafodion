////
/**
* @@@ START COPYRIGHT @@@
*
* Licensed to the Apache Software Foundation (ASF) under one
* or more contributor license agreements.  See the NOTICE file
* distributed with this work for additional information
* regarding copyright ownership.  The ASF licenses this file
* to you under the Apache License, Version 2.0 (the
* "License"); you may not use this file except in compliance
* with the License.  You may obtain a copy of the License at
*
*   http://www.apache.org/licenses/LICENSE-2.0
*
* Unless required by applicable law or agreed to in writing,
* software distributed under the License is distributed on an
* "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
* KIND, either express or implied.  See the License for the
* specific language governing permissions and limitations
* under the License.
*
* @@@ END COPYRIGHT @@@
*/
////

[[introduction]]
= Introduction

{project-name} is a Hadoop add-on service that provides transactional SQL on top of HBase. Typically, you
use {project-name} as the database for applications that require Online Transaction Processing (OLTP),
Operational Data Store (ODS), and/or strong reporting capabilities. You access {project-name} using
standard JDBC and ODBC APIs.

You may choose whether to add {project-name} to an existing Hadoop environment or to create a standalone
Hadoop environment specifically for Hadoop.

This guide assumes that a Hadoop environment exists upon which your provisioning {project-name}. Refer to
<<requirements-hadoop-software,Hadoop Software>> for information about what Hadoop software is required
{project-name}.

[[introduction-security-considerations]]
== Security Considerations

The following users need be considered for {project-name}:

* *Provisioning User*: A Linux-level user that performs the {project-name} provisioning tasks. This user ID
requires `sudo` access and passwordless ssh among the nodes where {project-name} is installed. In addition,
this user ID requires access to Hadoop distribution, HDFS, and HBase administrative users to change
respective environment's configuration settings per {project-name} requirements. Refer to
<<requirements-trafodion-provisioning-user,{project-name} Provisioning User>> for more information
about the requirements and usage associated with this user ID.

* *Runtime User*: A Linux-level user under which the {project-name} software runs. This user ID must be registered
as a user in the Hadoop Distributed File System (HDFS) to store and  access objects in HDFS, HBase, and Hive.
In addition, this  user ID requires passwordless access among the nodes where {project-name} is installed.
Refer to <<requirements-trafodion-runtime-user,{project-name} Runtime User>> for more information about this user ID.

* *{project-name} Database Users*: {project-name} users are managed by the {project-name} security features (grant, revoke, etc.),
which can be integrated with LDAP if so desired. These users are referred to as *database users* and
do not have direct access to the operating system. Refer to 
{docs-url}/sql_reference/index.html#register_user_statement[Register User],
{docs-url}/sql_reference/index.html#grant_statement[Grant], and other SQL statements
in the {docs-url}/sql_reference/index.html[{project-name} SQL Reference Manual] for
more information about managing {project-name} Database Users.
 +
 +
Optionally, you can enable {project-name} Security. If you do not enable security in {project-name}, then a client interface
to {project-name} may request a user name and password, but {project-name} ignores the user name and password entered in the
client interface, and the session runs as the database *root* user, `DB__ROOT`, without restrictions. If you want
to restrict users, restrict access to certain users only, or restrict access to an object or operation, then you must
enable security, which enforces authentication and authorization. Refer to
<<enable-security,Enable Security>> for more information about this option.

[[introduction-provisioning-options]]
== Provisioning Options

{project-name} ships with a set of scripts (the {project-name} Installer) that takes care of many of the installation and upgrade
tasks associated with the {project-name} software and its requirements. There is a separate set of scripts to remove {project-name},
if needed.

Currently, the {project-name} Installer is able to install {project-name} on select Cloudera and  Hortonworks Hadoop distributions only.
The {project-name} Installer limitations are noted as they apply in the different chapters below. For example, the {project-name} Installer
is less capable on SUSE than it is on RedHat/CentOS; you have to install the prerequisite software packages outside the {project-name} Installer.

The {project-name} Installer automates many of the tasks required to install/upgrade {project-name}, spanning from downloading and
installing required software packages and making required changes to your Hadoop environment via creating
the {project-name} runtime user ID to installing and starting {project-name}. It is, therefore,  highly recommend that
you use the {project-name} Installer for initial installation and upgrades of {project-name}. These steps are referred to as
"Script-Based Provisioning" in this guide. Refer to <<introduction-trafodion-installer, {project-name} Installer>> provides
usage information.

If, for any reason, you choose not to use the {project-name} Installer, then separate chapters provide
step-by-step recipes for the tasks required to install/upgrade {project-name}. These steps are referred to as
*Recipe-Based Provisioning* in this guide. It is assumed that you are well-versed in Linux and Hadoop
administrative tasks if using Recipe-Based Provisioning.

[[introduction-provisioning-activities]]
== Provisioning Activities

{project-name} provisioning is divided into the following main activities:

* *<<requirements,Requirements>>*: Activities and documentation required to install the {project-name} software.
These activities include tasks such as understanding hardware and operating system requirements,
Hadoop requirements, what software packages that need to be downloaded, configuration settings that need to be changed,
user IDs requirements, and so on.

* *<<prepare,Prepare>>*: Activities to prepare the operating system and the Hadoop ecosystem to run
{project-name}. These activities include tasks such as installing required software packages, configure
the {project-name} Installation User, gather information about the Hadoop environment, modify configuration
for different Hadoop services, and so forth.

* *<<install,Install>>*: Activities related to installing the {project-name} software. These activities
include tasks such as unpacking the {project-name} tar files, creating the {project-name} Runtime User,
creating {project-name} HDFS directories, installing the {project-name} software, and so forth.

<<<
* *<<upgrade,Upgrade>>*: Activities related to the upgrading the {project-name} software. These activities
include tasks such as shutting down {project-name}, installing a new version of the {project-name} software,
and so on. The upgrade tasks vary depending on the differences between the current and new release of
{project-name}. For example, an upgrade may or may not include an upgrade of the {project-name} metadata.

* *<<activate,Activate>>*: Activities related to starting the {project-name} software. These actives
include basic management tasks such as starting and checking the status of the {project-name} components,
performing basic smoke tests, and so forth.

* *<<remove,Remove>>*: Activities related to removing {project-name} from your Hadoop cluster.

[[introduction-provisioning-master-node]]
== Provisioning Master Node
All provisioning tasks are performed from a single node in the cluster, which must be part
of the Hadoop environment you're adding {project-name} to. This node is referred to as the
"*Provisioning Master Node*" in this guide.

The {project-name} Provisioning User must have access to all other nodes from the Provisioning
Master Node in order to perform provisioning tasks on the cluster.

[[introduction-trafodion-installer]]
== {project-name} Installer

The {project-name} Installer is a set of scripts automates most of the tasks requires to install/upgrade {project-name}.
You download the {project-name} Installer tar file from the {project-name} {download-url}[download] page.
Next, you unpack the tar file.

*Example*

```
$ mkdir $HOME/trafodion-installer
$ cd $HOME/trafodion-downloads
$ tar -zxf apache-trafodion-installer-1.3.0-incubating-bin.tar.gz -C $HOME/trafodion-installer
$ ls $HOME/trafodion-installer/installer
bashrc_default           tools                             traf_config_check           trafodion_apache_hadoop_install  traf_package_setup
build-version-1.3.0.txt  traf_add_user                     traf_config_setup           trafodion_config_default         traf_setup
dcs_installer            traf_apache_hadoop_config_setup   traf_create_systemdefaults  trafodion_install                traf_sqconfig
rest_installer           traf_authentication_conf_default  traf_getHadoopNodes         trafodion_license                traf_start
setup_known_hosts.exp    traf_cloudera_mods98              traf_hortonworks_mods98     trafodion_uninstaller
$ 
```

<<<
The {project-name} Installer supports two different modes:

1. *Guided Setup*: Prompts for information as it works through the installation/upgrade process. This mode is recommended for new users.
2. *Automated Setup*: Required information is provided in a pre-formatted bash-script configuration file, which is provided
via a command argument when running the {project-name} Installer thereby suppressing all prompts.
+
A template of the configuration file is available here within the installer directory: `trafodion_config_default`.
Make a copy of the file in your directory and populate the needed information.
+
Automated Setup is recommended since it allows you to record the required provisioning information information ahead of time.
Refer to <<introduction-trafodion-automated-setup,Automated Setup>> for information about how to
populate this file.

[[introduction-trafodion-installer-usage]]
=== Usage

The following shows help for the {project-name} Installer.

```
./trafodion_install --help

This script will install Trafodion. It will create a configuration
file (if one has not been created), setup of the environment needed
for Trafodion, configure HBase with Hbase-trx and co-processors needed,
and install a specified Trafodion build.

Options:
    --help             Print this message and exit
    --accept_license   If provided, the user agrees to accept all the
                       provisions in the Trafodion license.  This allows
                       for automation by skipping the display and prompt of
                       the Trafodion license.
    --config_file      If provided, all install prompts will be
                       taken from this file and not prompted for.
```

<<<
[[introduction-trafodion-installer-install-vs-upgrade]]
=== Install vs. Upgrade

The {project-name} Installer automatically detects whether you're performing an install
or an upgrade by looking for the {project-name} Runtime User in the `/etc/passwd` file.

* If the user ID doesn't exist, then the {project-name} Installer runs in install mode.
* If the user ID exists, then the {project-name} Installer runs in upgrade mode.


[[introduction-trafodion-installer-guided-setup]]
=== Guided Setup

By default, the {project-name} Installer runs in Guided Setup mode, which means
that it prompts you for information during the install/upgrade process.

Refer to the following sections for examples:

* <<install-guided-install, Guided Install>>
* <<upgrade-guided-upgrade, Guided Upgrade>>

[[introduction-trafodion-installer-automated-setup]]
=== Automated Setup

The `--config_file` option runs the {project-name} in Automated Setup mode.

Before running the {project-name} Installer with this option, you do the following:

1. Copy the `trafodion_config_default` file.
+
*Example*
+
```
cp trafodion_config_default my_config
```

2. Edit the new file using information you collect in the
<<prepare-gather-configuration-information,Gather Configuration Information>>
section in the <<prepare,Prepare>> chapter.

3. Run the {project-name} Installer in Automated Setup Mode
+
*Example*
+
```
./trafodion_installer --config_file my_config
```

NOTE: Your {project-name} Configuration File contains the password for the {project-name} Runtime User
and for the Distribution Manager. Therefore, we recommend that you secure the file in a manner
that matches the security policies of your organization. 

==== Example: Creating a {project-name} Configuration File

Using the instructions in <<prepare-gather-configuration-information,Gather Configuration Information>>
in the <<prepare,Prepare>> chapter, you record the following information.

[cols="30%l,50%,20%",options="header"]
|===
| ID                      | Information                                                                                | Setting                       
| ADMIN                   | Administrator user name for Apache Ambari or Cloudera Manager.                             | admin                         
| BACKUP_DCS_NODES        | List of nodes where to start the backup DCS Master components.                             | 
| CLOUD_CONFIG            | Whether you're installing {project-name} on a cloud environment.                                | N 
| CLOUD_TYPE              | What type of cloud environment you're installing {project-name} on.                             | 
| CLUSTER_NAME            | The name of the Hadoop Cluster.                                                            | Cluster 1
| DCS_BUILD               | Tar file containing the DCS component.                                                     | 
| DCS_PRIMARY_MASTER_NODE | The node where the primary DCS should run.                                                 | 
| DCS_SERVER_PARM         | Number of concurrent client sessions per node.                                             | 8
| ENABLE_HA               | Whether to run DCS in high-availability (HA) mode.                                         | N
| EPEL_RPM                | Location of EPEL RPM. Specify if you don't have access to the Internet.                    | 
| FLOATING_IP             | IP address if running DCS in HA mode.                                                      | 
| HADOOP_TYPE             | The type of Hadoop distribution you're installing {project-name} on.                            | cloudera
| HBASE_GROUP             | Linux group name for the HBASE administrative user.                                         | hbase
| HBASE_USER              | Linux user name for the HBASE administrative user.                                          | hbase
| HDFS_USER               | Linux user name for the HDFS administrative user.                                           | hdfs 
| HOME_DIR                | Root directory under which the `trafodion` home directory should be created.               | /home 
| INIT_TRAFODION          | Whether to automatically initialize the {project-name} database.                                | Y
| INTERFACE               | Interface type used for $FLOATING_IP.                                                      | 
| JAVA_HOME               | Location of Java 1.7.0_65 or higher (JDK).                                                 | /usr/java/jdk1.7.0_67-cloudera
| LDAP_CERT               | Full path to TLS certificate.                                                              | 
| LDAP_HOSTS              | List of nodes where LDAP Identity Store servers are running.                               | 
| LDAP_ID                 | List of LDAP unique identifiers.                                                           | 
| LDAP_LEVEL              | LDAP Encryption Level.                                                                     | 
| LDAP_PASSWORD           | Password for LDAP_USER.                                                                    | 
| LDAP_PORT               | Port used to communicate with LDAP Identity Store.                                         | 
| LDAP_SECURITY           | Whether to enable simple LDAP authentication.                                            | N   
| LDAP_USER               | LDAP Search user name.                                                                     | 
| LOCAL_WORKDIR           | The directory where the {project-name} Installer is located.                                    | /home/centos/trafodion-installer/installer
| MANAGEMENT_ENABLED      | Whether your installation uses separate management nodes.                                  | N
| MANAGEMENT_NODES        | The FQDN names of management nodes, if any.                                                | 
| NODE_LIST               | The FQDN names of the nodes where {project-name} will be installed.                             | trafodion-1 trafodion-2
| PASSWORD                | Administrator password for Apache Ambari or Cloudera Manager.                              | admin
| REST_BUILD              | Tar file containing the REST component.                                                    | 
| SQ_ROOT                 | Target directory for the {project-name} software.                                               | /home/trafodion/apache-trafodion-1.3.0-incubating-bin
| START                   | Whether to start {project-name} after install/upgrade.                                          | Y
| SUSE_LINUX              | Whether your installing {project-name} on SUSE Linux.                                           | false
| TRAF_PACKAGE            | The location of the {project-name} installation package tar file or core installation tar file. | /home/centos/trafodion-download/apache-trafodion-1.3.0-incubating-bin.tar.gz
| TRAF_USER               | The {project-name} runtime user ID. Must be `trafodion` in this release.                         | trafodion
| TRAF_USER_PASSWORD      | The password used for the `trafodion:trafodion` user ID.                                   | traf123
| URL                     | FQDN and port for the Distribution Manager's REST API.                                     | trafodion-1.apache.org:7180
|===

Next, you edit `my_config` to contain the following:

```
#!/bin/bash
# @@@ START COPYRIGHT @@@
#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#
# @@@ END COPYRIGHT @@@

#====================================================
# Trafodion Configuration File
# This file contains default values for the installer.

# Users can also edit this file and provide values for all parameters
# and then specify this file on the run line of trafodion_install.
# Example:
# ./trafodion_install --config_file <Trafodion-config-file>
# WARNING: This mode is for advanced users!
#
#=====================================================


#=====================================================
#Must be set to 'true' if on a SUSE linux system. If on another type of system
#this must be set to false.

export SUSE_LINUX="false"

# The working directory where Trafodion installer untars files, etc.
# do not change this unless you really know what you are doing
export TRAF_WORKDIR="/usr/lib/trafodion"

# This is the directory where the installer scripts were untarred to
export LOCAL_WORKDIR="/home/centos/trafodion-installer/installer"

# The maximum number of dcs servers, i.e. client connections
export DCS_SERVERS_PARM="8"

# "true" if this is an upgrade
export UPGRADE_TRAF="false"

# Trafodion userid, This is the userid the Trafodion instance will run under
export TRAF_USER="trafodion"

# Trafodion userid's password
export TRAF_USER_PASSWORD="traf123"

# a blank separated list of nodes in your cluster
# node names should include full domain names
#This can not be left blank!
export NODE_LIST="trafodion-1 trafodion-2"

# count of nodes in node list
export node_count="2"

# another list of the same nodes in NODE_LIST but specified in a pdsh usable format
# i.e.  "-w centos-cdh[1-6]"  or "-w node1 -w node2 -w node3"
export MY_NODES="-w trafodion-[1-2]"

# the directory prefix for the trafodion userid's $HOME directory
# i.e. /opt/home, not /opt/home/trafodion
export HOME_DIR="/home"

#JAVA HOME must be a JDK. Must include FULL Path. Must be 1.7.0_65 or higher.

export JAVA_HOME="/usr/java/jdk1.7.0_67-cloudera"

# If your machine doesn't have external internet access then you must
# specify the location of the EPEL rpm, otherwise leave blank and it
# will be installed from the internet
export EPEL_RPM=""

# full path of the Trafodion package tar file
export TRAF_PACKAGE="/home/centos/trafodion-download/apache-trafodion-1.3.0-incubating-bin.tar.gz"

# if TRAF_PACKAGE wasn't specified then these two values must be specified
# TRAF_BUILD is the trafodion_server tar file
# DCS_BUILD is the DCS tar file
# REST_BUILD is the REST tar file
export TRAF_BUILD=""
export DCS_BUILD=""
export REST_BUILD=""
# Either "cloudera" or "hortonworks" (all lowercase)
export HADOOP_TYPE="cloudera"

# The URL for Cloudera/Hortonworks REST API (i.e. node1.host.com:8080)
export URL="trafodion-1.apache.org:7180"

# Cloudera/Hortonworks UI admin's userid and password
export ADMIN="admin"
export PASSWORD="admin"

# hadoop cluster name
export CLUSTER_NAME=""

# the Hadoop HDFS userid
export HDFS_USER="hdfs"

# the Hadoop HBase userid and group
export HBASE_USER="hbase"
export HBASE_GROUP="hbase"

# The hadoop HBase service name
export HBASE="hbase"

# full path of where to install Trafodion to
# Example is used below. If $HOME_DIR or $TRAF_USER have been changed
# then this will need to be changed.
# On an upgrade, it is recommend to choose a different directory.
# First time install : /home/trafodion/traf
# On Upgrade: /home/trafodion/traf_<date>
# By doing this the previous version will remain and allow for an easier rollback.
export SQ_ROOT="/home/trafodion/apache-trafodion-1.3.0-incubating-bin"

# Start Trafodion after install completes
export START="Y"

# initialize trafodion after starting
export INIT_TRAFODION="Y"

# full path to the sqconfig file
# Default is to leave as is and this file will be created.
export SQCONFIG=""

export CONFIG_COMPLETE="true"

#Turn on simple security. MUST have existing LDAP configured.
export LDAP_SECURITY="N"

#Name of LDAP Config file
export LDAP_AUTH_FILE="traf_authentication_config_${HOSTNAME}"
```

Once completed, run the {project-name} Installer with the `--config_file` option.

Refer to the following sections for examples:

* <<install-automated-install, Automated Install>>
* <<upgrade-automated-upgrade, Automated Upgrade>>

[[introduction-trafodion-provisioning-directories]]
== {project-name} Provisioning Directories

{project-name} stores its provisioning information in the following directories on each node in the cluster:

* `/etc/trafodion`: Configurtion information.
* `/usr/lib/trafodion`: Copies of the installer files.





